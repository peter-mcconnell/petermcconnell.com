<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Peter McConnell :: Ponderings from a Linux Systems engineer</title>
    <link>https://www.petermcconnell.com/posts/</link>
    <description>Recent content in Posts on Peter McConnell :: Ponderings from a Linux Systems engineer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Peter McConnell 2023</copyright>
    <lastBuildDate>Fri, 30 Dec 2022 20:34:57 +0000</lastBuildDate><atom:link href="https://www.petermcconnell.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What is DevOps?</title>
      <link>https://www.petermcconnell.com/posts/whatisdevops/</link>
      <pubDate>Fri, 30 Dec 2022 20:34:57 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/whatisdevops/</guid>
      <description>The term &amp;ldquo;devops&amp;rdquo; has been floating around since the late 2000s and frankly has always annoyed me. Not that I think the intent was bad but rather the adoption was so varied and confusing that simply saying the word out loud seemed to make things worse and lead to fear and confusion. I&amp;rsquo;d like to make &amp;ldquo;DevOps&amp;rdquo; the &amp;ldquo;Voldermort&amp;rdquo; of tech buzzwords - &amp;ldquo;He-Who-Must-Not-Be-Named&amp;rdquo;. This happened with Agile also which is even more confusing given it has a &amp;ldquo;manifesto&amp;rdquo; that&amp;rsquo;s all but a single paragraph, but I&amp;rsquo;ll leave that for another day.</description>
      <content>&lt;p&gt;The term &amp;ldquo;devops&amp;rdquo; has been floating around since the late  2000s and frankly has
always annoyed me. Not that I think the intent was bad but rather the adoption
was so varied and confusing that simply saying the word out loud seemed to make
things worse and lead to fear and confusion. I&amp;rsquo;d like to make &amp;ldquo;DevOps&amp;rdquo; the
&amp;ldquo;Voldermort&amp;rdquo; of tech buzzwords - &amp;ldquo;He-Who-Must-Not-Be-Named&amp;rdquo;. This happened with
Agile also which is even more confusing given it has a &amp;ldquo;manifesto&amp;rdquo; that&amp;rsquo;s all
but a single paragraph, but I&amp;rsquo;ll leave that for another day.&lt;/p&gt;
&lt;p&gt;The Wikipedia (&lt;a href=&#34;https://en.wikipedia.org/wiki/DevOps&#34;&gt;https://en.wikipedia.org/wiki/DevOps&lt;/a&gt;) page for DevOps is fairly
hand-wavey which somewhat highlights the issue. Like most documents talking to
&amp;ldquo;organisational change&amp;rdquo; it&amp;rsquo;s a word-salad with no real actionable takeaways.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve had several &amp;ldquo;DevOps&amp;rdquo; jobs and each of them were functionally and
organisationally different. All projects were delivered but done so more often
than not via silos. Wasn&amp;rsquo;t this the problem &amp;ldquo;DevOps&amp;rdquo; was meant to solve?&lt;/p&gt;
&lt;p&gt;Speaking of &amp;hellip; What &lt;em&gt;is&lt;/em&gt; the problem to solve? Shipping code to production
quickly and reliably. In ye olden times there were issues of siloed development
teams and operations teams meaning the devs wouldn&amp;rsquo;t optimise for production
workloads and the operators wouldn&amp;rsquo;t have a clue what they were shipping onto
their servers. There&amp;rsquo;s a lot of domain expertise in both camps - asking people
to become experts of both was unreasonable.&lt;/p&gt;
&lt;p&gt;But that was also a different time &amp;hellip; we didn&amp;rsquo;t have the abundance of tooling
and services that we do today. Kubernetes didn&amp;rsquo;t exist. Docker didn&amp;rsquo;t exist.
Cloud offerings were pretty light. With the tools available today, asking SWEs
to take on more responsibility to account for their applications in production
is a reasonable ask.&lt;/p&gt;
&lt;h2 id=&#34;so-what-should-we-do&#34;&gt;so what should we do?&lt;/h2&gt;
&lt;p&gt;Frankly I think we&amp;rsquo;re now in a world that looks more like the pre-devops days.
SWE teams are no longer handing over a package of code and saying &amp;ldquo;hey, take my
source code, install these dependencies and run this&amp;rdquo; but are now in control of
their applications deployment manifest and can containerise their applications.
The original problem to solve feels like much smaller a problem now.&lt;/p&gt;
&lt;p&gt;Operators can run a platform such as Kubernetes which for the most part the
other engineering teams can treat like a PAAS. &amp;ldquo;How will devs know how to
configure their apps to run on the platform&amp;rdquo; - they&amp;rsquo;ll have to learn. Somehow.
Guardrails should be put in place (e.g. policies) to stop people &amp;ldquo;doing bad
things&amp;rdquo; but it shouldn&amp;rsquo;t go as far as &amp;ldquo;that devops engineer will write your
cicd config&amp;rdquo; or &amp;ldquo;that devops engineer will write your kubernetes config&amp;rdquo;. Teams
MUST own their config, and to own it they need to understand it.&lt;/p&gt;
&lt;p&gt;So it shouldn&amp;rsquo;t be a team or a job title. There shouldn&amp;rsquo;t be &amp;ldquo;devops tools&amp;rdquo; or a
&amp;ldquo;devops environment&amp;rdquo;. A problem can never be &amp;ldquo;a devops issue&amp;rdquo;. You might have a
kubernetes team, an OPA/IAM/network policy team, a streaming services team etc.
Just don&amp;rsquo;t have a &amp;ldquo;devops&amp;rdquo; team.&lt;/p&gt;
&lt;p&gt;We shouldn&amp;rsquo;t give it a new name either. Stop giving everything a name just so
you can sell books and tshirts. This just creates distance from the problem to
solve - we all just want to ship code reliably so that our business meets its
goals and so that we don&amp;rsquo;t spend overtime fixing bugs or doing manual work that
could have been done by a computer.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>A quick introduction to basic debugging tools for linux systems</title>
      <link>https://www.petermcconnell.com/posts/linuxtools/</link>
      <pubDate>Fri, 30 Dec 2022 14:28:12 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/linuxtools/</guid>
      <description>The scope of this article is to cover the best common-use debugging tools available on Linux systems.
Firstly: let me qualify &amp;ldquo;basic&amp;rdquo;. I&amp;rsquo;m using this term because the breadth of debugging tools on Linux is so large. &amp;ldquo;basic&amp;rdquo; does not mean that these tools are super simple to understand deeply or if you aren&amp;rsquo;t already an expert in them that you are somehow &amp;ldquo;noob&amp;rdquo;; that&amp;rsquo;s not the case at all.</description>
      <content>&lt;p&gt;The scope of this article is to cover the best common-use debugging tools available on Linux systems.&lt;/p&gt;
&lt;p&gt;Firstly:  let me qualify &amp;ldquo;basic&amp;rdquo;. I&amp;rsquo;m using this term because the breadth of debugging tools on Linux is so large. &amp;ldquo;basic&amp;rdquo; does not mean that these tools are super simple to understand deeply or if you aren&amp;rsquo;t already an expert in them that you are somehow &amp;ldquo;noob&amp;rdquo;; that&amp;rsquo;s not the case at all.&lt;/p&gt;
&lt;p&gt;Secondly: there is no inventing being done here. I&amp;rsquo;m just surfacing information in this article which you can already find in the &lt;code&gt;man&lt;/code&gt; pages. I would strongly recommend you check the relevant man page for the tool you find of interest in this article.&lt;/p&gt;
&lt;p&gt;Thirdly: for the curious, these tools generally get their information from existing counters and statistics in &lt;code&gt;/proc/&lt;/code&gt; and &lt;code&gt;/sys/&lt;/code&gt;. In the man pages for these tools you can see a &lt;code&gt;FILES&lt;/code&gt; section which details the data source for the given tool.&lt;/p&gt;
&lt;h2 id=&#34;crisis-tools&#34;&gt;&amp;ldquo;crisis tools&amp;rdquo;&lt;/h2&gt;
&lt;p&gt;This section is taken from Brendan Gregg&amp;rsquo;s book &lt;a href=&#34;https://amzn.to/3I9iU49%5D&#34;&gt;&amp;lsquo;System Performance&amp;rsquo; (4.1.2)&lt;/a&gt;. It covers not only where you can install some of the binaries mentioned in this article but also other useful tools for debugging. All credit to him for this list.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;package&lt;/th&gt;
&lt;th&gt;provides&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;procps&lt;/td&gt;
&lt;td&gt;ps(1), vmstat(8), uptime(1), top(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;util-linux&lt;/td&gt;
&lt;td&gt;dmesg(1), lsblk(1), lscpu(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sysstat&lt;/td&gt;
&lt;td&gt;iostat(1), mpstat(1), pidstat(1), sar(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iproute2&lt;/td&gt;
&lt;td&gt;ip(8), ss(8), nstat(8), tc(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;numactl&lt;/td&gt;
&lt;td&gt;numastat(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;linux-tools-common linux-tools-$(uname -r)&lt;/td&gt;
&lt;td&gt;perf(1), turbostat(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;bcc-tools (aka bpfcc-tools)&lt;/td&gt;
&lt;td&gt;opensnoop(8), execsnoop(8), runqlat(8), runqlen(8), softirqs(8), hardirqs(8), ext4slower(8), ext4dist(8), biotop(8), biosnoop(8), biolatency(8), tcptop(8), tcplife(8), trace(8), argdist(8), funccount(8), stackcount(8), profile(8) and more &amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;bpftrace&lt;/td&gt;
&lt;td&gt;bpftrace, basic versions of opensnoop(8), iolatency(8), iosnoop(8), bitesize(8), funccount(8), kprobe(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;perf-tools-unstable&lt;/td&gt;
&lt;td&gt;Ftrace versions of opensnoop(8), execsnoop(8), iolatency(8), iosnoop(8), bitesize(8), funccount(8), kprobe(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;trace-cmd&lt;/td&gt;
&lt;td&gt;trace-cmd(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nicstat&lt;/td&gt;
&lt;td&gt;nicstat(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ethtool&lt;/td&gt;
&lt;td&gt;ethtool(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tiptop&lt;/td&gt;
&lt;td&gt;tiptop(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;msr-tools&lt;/td&gt;
&lt;td&gt;rdmsr(8), wrmsr(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;github.com/brendangregg/msr-cloud-tools&lt;/td&gt;
&lt;td&gt;showboost(8), cpuhot(8), cputemp(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;github.com/brendangregg/pmc-cloud-tools&lt;/td&gt;
&lt;td&gt;pmcarch(8), cpucache(8), lcache(8), tlbstat(8), resstalls(8)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;top&#34;&gt;top&lt;/h2&gt;
&lt;p&gt;When: A reasonable first place to look for an issue.&lt;/p&gt;
&lt;p&gt;This is a command-line utility in Linux that allows users to view the processes running on their system and monitor their resource usage in real-time. It can be used to identify performance bottlenecks, track the usage of system resources, and troubleshoot issues on a Linux system.&lt;/p&gt;
&lt;p&gt;The output of top will include a list of processes running on the system, along with the following information for each process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The process ID (PID)&lt;/li&gt;
&lt;li&gt;The user owning the process&lt;/li&gt;
&lt;li&gt;The CPU and memory usage of the process&lt;/li&gt;
&lt;li&gt;The command that started the process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the output you can identify some performance issues with your system. For example, if a single process is consuming a large amount of CPU or memory resources, it could be causing performance issues for your system. Similarly, if multiple processes are consuming high amounts of resources, it could indicate that your system is struggling to keep up with demand and may be a bottleneck.&lt;/p&gt;
&lt;p&gt;One common problem that &lt;code&gt;top&lt;/code&gt; can help identify is resource contention which occurs when multiple processes or applications are competing for the same system resources.&lt;/p&gt;
&lt;p&gt;I suspect this tool is familiar to many of you already:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/top.jpg&#34; alt=&#34;top example&#34; title=&#34;top example&#34;&gt;&lt;/p&gt;
&lt;p&gt;However what you may not realise is that you can pull much more data from it. Press &amp;lsquo;f&amp;rsquo; when in top to access the fields management view and select other columns to display:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/top_fields.jpg&#34; alt=&#34;top fields management&#34; title=&#34;top fields management view&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;htop&lt;/code&gt; is a visually prettier alternative to &lt;code&gt;top&lt;/code&gt; and that can make understanding the system at a glance easier.&lt;/p&gt;
&lt;h2 id=&#34;mpstat&#34;&gt;mpstat&lt;/h2&gt;
&lt;p&gt;When: you think there&amp;rsquo;s an issue with the CPU utilization.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mpstat&lt;/code&gt; is a command-line tool that is used to monitor the performance of a Linux system by displaying the CPU usage of each processor and the overall system.&lt;/p&gt;
&lt;p&gt;Imagine that you are the system administrator of a web server that is experiencing slow performance and perhaps even downtime. You check the web server logs but nothing obvious is standing out so you begin to suspect there&amp;rsquo;s something else wrong with the system. One general check we can do is on the CPU cores - this is where &lt;code&gt;mpstat&lt;/code&gt; comes in.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mpstat -P ALL
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will display the CPU usage statistics for all CPU cores on the system. The output will look something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 4.9.0-8-amd64 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;server.petermcconnell.com&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;  01/01/2023  _x86_64_    &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;02:34:56 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;02:34:56 AM  all    20.00    0.00    5.00    0.00    0.00    0.00    0.00    0.00    0.00   75.00
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;02:34:56 AM    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;    22.50    0.00    6.25    0.00    0.00    0.00    0.00    0.00    0.00   71.25
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;02:34:56 AM    &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;     7.50    0.00    3.75    0.00    0.00    0.00    0.00    0.00    0.00   88.75
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first line shows the Linux version, hostname, and CPU architecture. The second line displays the column headers, which show the various metrics that are being measured. The third line, labeled &amp;ldquo;all,&amp;rdquo; shows the overall CPU usage for all CPU cores combined. The fourth and fifth lines show the CPU usage for each individual CPU core.&lt;/p&gt;
&lt;p&gt;In this example, we can see that CPU 0 is running at a higher utilization than CPU 1. This could indicate that there is an issue with CPU 0 that is causing it to work harder than it should. To further investigate the issue we can opt to print these statistics every second by adding a &amp;ldquo;1&amp;rdquo; to the end of the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mpstat -P ALL &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will print statistics from each core every second, showing the current CPU usage. By watching the output over time, we can see if there are any patterns or spikes in the usage of a particular CPU core.&lt;/p&gt;
&lt;p&gt;If we notice that one of the CPU cores is consistently running at a higher utilization than the others, we can try to identify the cause of the problem. One way to do this is by using the &lt;code&gt;top&lt;/code&gt; command to see which processes are using the most CPU resources. It could be that the program itself is misconfigured and not properly distributing load over the available cores.&lt;/p&gt;
&lt;h2 id=&#34;iostat&#34;&gt;iostat&lt;/h2&gt;
&lt;p&gt;When: you think there&amp;rsquo;s an issue with IO.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;iostat&lt;/code&gt; tool is a command-line utility in Linux that allows users to monitor input/output (I/O) statistics for devices, partitions, and network filesystems. It can be used to identify performance bottlenecks and track the usage of system resources by I/O operations.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;iostat&lt;/code&gt;, you need to specify the interval at which you want to collect data, as well as the devices or partitions you want to monitor. For example, the following command will display I/O statistics for all devices every 2 seconds, 5 times:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ iostat -p ALL &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;myputer&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;avg-cpu:  %user   %nice %system %iowait  %steal   %idle
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           1.40   15.48    4.48    0.99    0.00   77.66
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop0             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop1             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop2             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop3             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop4             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop5             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop6             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loop7             0.00         0.00         0.00         0.00          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sda               4.83        79.27       106.76         0.00     &lt;span style=&#34;color:#ae81ff&#34;&gt;858983&lt;/span&gt;    &lt;span style=&#34;color:#ae81ff&#34;&gt;1156820&lt;/span&gt;          &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;... repeat
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can also get more simple summaries - for example, CPU utilization report:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ iostat -c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;urputer&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;avg-cpu:  %user   %nice %system %iowait  %steal   %idle
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           1.36   15.09    4.37    0.95    0.00   78.22
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Or a device utilization report:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;iostat -d -h -p ALL
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;xerxes&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd Device
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop5
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop6
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       0.0k       0.0k       0.0k loop7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     4.82        73.5k       103.6k         0.0k     841.2M       1.2G       0.0k sda
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.01         0.3k         0.0k         0.0k       3.1M       0.5k       0.0k sda1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       2.0k       0.0k       0.0k sda2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     4.71        73.1k       103.6k         0.0k     836.0M       1.2G       0.0k sda5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We&amp;rsquo;re seeing a lot of devices here which are showing to be inactive. We can easily hide those from view - rarely when debugging an issue do you want to see statistics for a device that isn&amp;rsquo;t being used. To hide these, pass &lt;code&gt;-z&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;iostat -d -h -p ALL -z
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;xerxes&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd Device
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     4.84        72.1k       103.1k         0.0k     841.2M       1.2G       0.0k sda
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.01         0.3k         0.0k         0.0k       3.1M       0.5k       0.0k sda1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     0.00         0.0k         0.0k         0.0k       2.0k       0.0k       0.0k sda2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     4.73        71.7k       103.1k         0.0k     836.0M       1.2G       0.0k sda5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;By analyzing this data, you can identify performance issues with your devices or partitions. For example, if the number of read or write operations is consistently high, it could indicate that the device or partition is heavily used and may be a bottleneck. Similarly, if the average time taken for each I/O operation is consistently high, it could indicate that the device or partition is struggling to keep up with demand.&lt;/p&gt;
&lt;p&gt;A common problem that &lt;code&gt;iostat&lt;/code&gt; can help identify is disk saturation, which occurs when a disk is being used to its maximum capacity and can&amp;rsquo;t keep up with the demand for I/O operations. This can lead to slow performance and potential data loss. In &lt;code&gt;iostat&lt;/code&gt; output this problem may manifest as a consistently high percentage of time the device is busy with I/O operations and a high average time taken for each I/O operation.&lt;/p&gt;
&lt;h2 id=&#34;sar&#34;&gt;sar&lt;/h2&gt;
&lt;p&gt;When: general purpose. you think there&amp;rsquo;s an issue with CPU, Memory, Network or Block devices. Can record findings to files on disk for comparisson later (which is the main selling point of &lt;code&gt;sar&lt;/code&gt; over, say &lt;code&gt;vmstat&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;sar&lt;/code&gt; (System Activity Report) tool is a command-line utility in Linux that allows users to monitor various system performance metrics over time. It can be used to identify performance bottlenecks, track the usage of system resources, and troubleshoot issues on a Linux system.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;sar&lt;/code&gt;, you need to specify the interval at which you want to collect data and the system performance metrics you want to monitor. For example, the following command will display CPU utilization statistics every 2 seconds:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sar &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output of sar will include various performance metrics, depending on the options you specify. Some of the metrics that sar can monitor include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU utilization&lt;/li&gt;
&lt;li&gt;Memory usage&lt;/li&gt;
&lt;li&gt;Disk I/O activity&lt;/li&gt;
&lt;li&gt;Network activity&lt;/li&gt;
&lt;li&gt;Load average (a measure of the system&amp;rsquo;s CPU and I/O utilization)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By analyzing this data, you can identify any performance issues with your system. For example, if the CPU utilization is consistently high, it could indicate that your system is struggling to keep up with demand and may be a bottleneck. Similarly, if the memory usage is consistently high, it could indicate that your system is running out of available memory.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sar&lt;/code&gt; stores its reports in &lt;code&gt;/var/log/sysstat/&lt;/code&gt; by default and will look for files in this directory when you ask it for some reports. The file it looks for changes depending on the INTERVAL value passed to it. This can result in an error if a report isn&amp;rsquo;t available from yesterday:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# -B tells sar to create a report on paging statistics&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sar -B
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Cannot open /var/log/sysstat/sa30: No such file or directory
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Please check &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; data collecting is enabled
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can specify &lt;code&gt;0&lt;/code&gt; as the interval time which tells &lt;code&gt;sar&lt;/code&gt; to use statistics for the time since the system was started:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sar &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; -B
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;herputer&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17:51:10     pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17:51:10        66.01     99.20   3074.99      0.38   1853.06      0.00      0.00      0.00      0.00
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;sar&lt;/code&gt; can also be used to report on I/O and transfer rate statistics:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sar &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; -b
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;hisputer&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17:53:49          tps      rtps      wtps      dtps   bread/s   bwrtn/s   bdscd/s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17:53:49         4.64      1.32      3.32      0.00    130.43    196.40      0.00
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&amp;hellip; and block devices:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sar &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; -d
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Linux 5.4.0-72-generic &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;ourputer&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; 	30/12/22 	_x86_64_	&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; CPU&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17:55:12          DEV       tps     rkB/s     wkB/s     dkB/s   areq-sz    aqu-sz     await     %util
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17:55:12       dev8-0      4.63     64.81     97.66      0.00     35.13      0.05     11.69      2.11
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&amp;hellip; and more. &lt;code&gt;sar&lt;/code&gt; is a very powerful tool - please check out the man page for more info.&lt;/p&gt;
&lt;h2 id=&#34;vmstat&#34;&gt;vmstat&lt;/h2&gt;
&lt;p&gt;When: you think there&amp;rsquo;s an issue with memory usage or I/O activity.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;vmstat&lt;/code&gt; (Virtual Memory Statistics) tool is a command-line utility in Linux that allows users to monitor various system performance metrics, including memory usage and I/O activity. It can be used to identify performance bottlenecks, track the usage of system resources, and troubleshoot issues on a Linux system.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;vmstat&lt;/code&gt; you need to specify the interval at which you want to collect data. For example, the following command will display system performance statistics every 2 seconds:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vmstat &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output of vmstat will include the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The number of processes in various states (e.g. running, waiting, blocked)&lt;/li&gt;
&lt;li&gt;The amount of memory being used, including the amount of available memory&lt;/li&gt;
&lt;li&gt;The number of page faults (when a process requests a page of memory that is not in physical memory and must be retrieved from disk)&lt;/li&gt;
&lt;li&gt;The amount of I/O activity, including the number of read and write operations per second&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;free&#34;&gt;free&lt;/h2&gt;
&lt;p&gt;When: you want to assess the state of memory on a machine.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;free -w -h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              total        used        free      shared     buffers       cache   available
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Mem:           15Gi       1.1Gi        12Gi       224Mi        95Mi       1.4Gi        13Gi
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Swap:         2.0Gi          0B       2.0Gi
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here we see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The total amount of available and used memory&lt;/li&gt;
&lt;li&gt;The amount of used and available swap space (virtual memory on disk used to store data when the system&amp;rsquo;s physical memory is full)&lt;/li&gt;
&lt;li&gt;The number of used and available buffers (a type of cache used to store data temporarily) and cache (data stored in memory to speed up access to frequently used data)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lsblk&#34;&gt;lsblk&lt;/h2&gt;
&lt;p&gt;When: you assume there&amp;rsquo;s an issue with the block devices and want to first check everything is in place.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;lsblk&lt;/code&gt; (List Block Devices) command is a command-line utility in Linux that allows users to view a list of block devices (e.g. hard drives, SSDs, USB drives) attached to their system. It can be used to view the available block devices, their mount points, and their partition layouts. You may want to use this tool to validate if block devices are available and mounted.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;lsblk&lt;/code&gt;, you simply need to enter the command followed by any desired options. The following command will display a list of all block devices on the system:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ lsblk -f
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME   FSTYPE LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sda
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;├─sda1 vfat         29C1-1F85                               511M     0% /boot/efi
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;├─sda2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;└─sda5 ext4         e3a6ec94-05ab-4e15-a310-e5797a2c55e9    419G     3% /
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output of lsblk will include the following information for each block device:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The device name (e.g. sda, sdb)&lt;/li&gt;
&lt;li&gt;The device type (e.g. disk, partition)&lt;/li&gt;
&lt;li&gt;The size of the device&lt;/li&gt;
&lt;li&gt;The mount point (if the device is mounted)&lt;/li&gt;
&lt;li&gt;The filesystem type (if the device is formatted with a filesystem)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;df&#34;&gt;df&lt;/h2&gt;
&lt;p&gt;When: you&amp;rsquo;re aware of disk space issues and want to check the current availability.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;df&lt;/code&gt; (Disk Free) command is a command-line utility in Linux that allows users to view the amount of available and used disk space on their system. It can be used to identify if a disk is approaching or at capacity.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;df&lt;/code&gt;, you simply need to enter the command followed by any desired options. The following command will display the total amount of available and used disk space on the system:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;df -h /
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Filesystem      Size  Used Avail Use% Mounted on
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/dev/sda5       457G   15G  420G   4% /
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The output of df will include the following information for each file system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The file system name (e.g. /dev/sda1)&lt;/li&gt;
&lt;li&gt;The total size of the file system&lt;/li&gt;
&lt;li&gt;The amount of used and available space on the file system&lt;/li&gt;
&lt;li&gt;The percentage of used space on the file system&lt;/li&gt;
&lt;li&gt;The mount point (the location where the file system is mounted in the directory structure)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;perf&#34;&gt;perf&lt;/h2&gt;
&lt;p&gt;When: you are aware of a processing issue and want to understand which process it&amp;rsquo;s coming from, or you want to drill into the process to understand why it&amp;rsquo;s not performing to the expected standard.&lt;/p&gt;
&lt;p&gt;This tool allows users to monitor various performance metrics and events on their system. It can be used to identify performance bottlenecks, track the usage of system resources, and troubleshoot issues on a Linux system. Unlike the other tools in this article &lt;code&gt;perf&lt;/code&gt; allows us to actually peek into the running program to see which parts of it are consuming cpu cycles. This is an incredibly valuable tool to have for those wanting to performance engineer on Linux and I have a practical example of this detailed in &lt;a href=&#34;https://www.petermcconnell.com/posts/perf_eng_with_py12/&#34;&gt;https://www.petermcconnell.com/posts/perf_eng_with_py12/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;perf&lt;/code&gt;, you need to specify the type of performance data you want to collect, as well as the specific events or metrics you want to monitor. To get general cpu profiling you can run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf top -a
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_top.jpg&#34; alt=&#34;perf top example&#34; title=&#34;perf top example&#34;&gt;&lt;/p&gt;
&lt;p&gt;Perf also allows you to gather performance statistics. For example, the following command will collect CPU performance data for the cpu-clock event:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf stat -e cpu-clock
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;^C
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; Performance counter stats &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;system wide&amp;#39;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         11,633.97 msec cpu-clock                 &lt;span style=&#34;color:#75715e&#34;&gt;#    3.998 CPUs utilized&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;       2.909972618 seconds time elapsed
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The scope of what you can do with &lt;code&gt;perf&lt;/code&gt; is huge - too large for this article, but I couldn&amp;rsquo;t leave it off the list. Perhaps a &lt;code&gt;perf&lt;/code&gt; deep dive article will come here soon &amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;uptime&#34;&gt;uptime&lt;/h2&gt;
&lt;p&gt;When: you want to get a quick understanding of system load over the past 1, 5, 15 minutes or want to see how long the machine has been up for.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;uptime
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;19:26:35 up  5:12,  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; user,  load average: 0.33, 0.37, 0.37
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;further-reading&#34;&gt;further reading&lt;/h2&gt;
&lt;p&gt;The Linux Programming Interface book is a fantastic book to learn the Linux fundamentals. In particular it breaks down virtual memory into understandable chunks and also introduces some of the debugging tools mentioned in this article:&lt;/p&gt;


&lt;a href=&#34;https://www.amazon.com/Linux-Programming-Interface-System-Handbook/dp/1593272200?crid=1DXMBKFNYR6I4&amp;keywords=the+linux+programming+interface&amp;qid=1672318042&amp;sprefix=the+linux+programming+interfa%2Caps%2C183&amp;sr=8-1&amp;linkCode=li2&amp;tag=mobile052c67f-20&amp;linkId=5a628a4a0310f010f8843eec26340d21&amp;language=en_US&amp;ref_=as_li_ss_il&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;https://s.cdnshm.com/catalog/pt/t/33820519/linux-programming-interface.jpg&#34; height=&#34;180&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mobile052c67f-20&amp;language=en_US&amp;l=li2&amp;o=1&amp;a=1593272200&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;


&lt;p&gt;Systems Performance by Brendan Gregg is full of amazing material that also covers the tools in this article but goes into much greater depth and covers the likes of &lt;code&gt;bpf&lt;/code&gt; which wasn&amp;rsquo;t touched upon in this article:&lt;/p&gt;


&lt;a href=&#34;https://www.amazon.com/Systems-Performance-Brendan-Gregg/dp/0136820158?crid=2J7NSUPP1LBQ2&amp;keywords=systems+performance+enterprise+and+the+cloud&amp;qid=1672315747&amp;sprefix=systems+performance%2Caps%2C167&amp;sr=8-1&amp;linkCode=li2&amp;tag=mobile052c67f-20&amp;linkId=042c48313bcd6eae20ae98499600e515&amp;language=en_US&amp;ref_=as_li_ss_il&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; height=&#34;180&#34; src=&#34;https://m.media-amazon.com/images/W/WEBP_402378-T1/images/I/51Drvdub7TL._SX646_BO1,204,203,200_.jpg&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mobile052c67f-20&amp;language=en_US&amp;l=li2&amp;o=1&amp;a=0136820158&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;


&lt;p&gt;I&amp;rsquo;d also recommend checking out Branden Gregg&amp;rsquo;s website - lots of solid content in there: &lt;a href=&#34;https://www.brendangregg.com/&#34;&gt;https://www.brendangregg.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.brendangregg.com/Perf/linux_observability_tools.png&#34; alt=&#34;linux observability tools&#34; title=&#34;linux observability tools&#34;&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Perf engineering with Python 3.12</title>
      <link>https://www.petermcconnell.com/posts/perf_eng_with_py12/</link>
      <pubDate>Mon, 26 Dec 2022 22:54:29 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/perf_eng_with_py12/</guid>
      <description>overview 3.12 brings perf profiling! In this article we take a look at how the new perf profiling support helps reduce our dummy Python script from 36 seconds to 0.8 seconds. We&amp;rsquo;ll introduce the Linux tool perf and also FlameGraph.pl, look at some disassembly and go bug hunting. You can view the code for this article here: https://github.com/peter-mcconnell/petermcconnell.com/tree/main/assets/dummy/perf_py_proj
Take a second to go check out https://docs.python.org/3.12/howto/perf_profiling.html and indeed the changelog at https://www.</description>
      <content>&lt;h2 id=&#34;overview&#34;&gt;overview&lt;/h2&gt;
&lt;p&gt;3.12 brings perf profiling! In this article we take a look at how the new perf
profiling support helps reduce our dummy Python script from 36 seconds to 0.8
seconds. We&amp;rsquo;ll introduce the Linux tool &lt;code&gt;perf&lt;/code&gt; and also &lt;code&gt;FlameGraph.pl&lt;/code&gt;, look
at some disassembly and go bug hunting. You can view the code for this article
here: &lt;a href=&#34;https://github.com/peter-mcconnell/petermcconnell.com/tree/main/assets/dummy/perf_py_proj&#34;&gt;https://github.com/peter-mcconnell/petermcconnell.com/tree/main/assets/dummy/perf_py_proj&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Take a second to go check out &lt;a href=&#34;https://docs.python.org/3.12/howto/perf_profiling.html&#34;&gt;https://docs.python.org/3.12/howto/perf_profiling.html&lt;/a&gt; and indeed the changelog at &lt;a href=&#34;https://www.python.org/downloads/release/python-3120a3/&#34;&gt;https://www.python.org/downloads/release/python-3120a3/&lt;/a&gt;. The important part (for this post) from these links is:&lt;/p&gt;
&lt;p&gt;&amp;quot;&amp;quot;&amp;quot;
The Linux perf profiler is a very powerful tool that allows you to profile and obtain information about the performance of your application. perf also has a very vibrant ecosystem of tools that aid with the analysis of the data that it produces.&lt;/p&gt;
&lt;p&gt;The main problem with using the perf profiler with Python applications is that perf only allows to get information about native symbols, this is, the names of the functions and procedures written in C. This means that the names and file names of the Python functions in your code will not appear in the output of the perf.&lt;/p&gt;
&lt;p&gt;Since Python 3.12, the interpreter can run in a special mode that allows Python functions to appear in the output of the perf profiler. When this mode is enabled, the interpreter will interpose a small piece of code compiled on the fly before the execution of every Python function and it will teach perf the relationship between this piece of code and the associated Python function using perf map files.
&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;
&lt;h2 id=&#34;writing-a-bad-program&#34;&gt;writing a &amp;ldquo;bad&amp;rdquo; program&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;m excited to try this, so lets get going. Firstly lets create a python script for us to profile. I&amp;rsquo;m doing this before installing Python 3.12 as I want to create a FlameGraph of how this process looks in 3.10 verses 3.12. Here we have a script that attempts to perform lookups against a large list:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;run_dummy&lt;/span&gt;(numbers):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; findme &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; findme &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; numbers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;found&amp;#34;&lt;/span&gt;, findme)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;missed&amp;#34;&lt;/span&gt;, findme)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; __name__ &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# create a large sized input to show off inefficiency&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numbers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [i &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;20000000&lt;/span&gt;)]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()  &lt;span style=&#34;color:#75715e&#34;&gt;# get the current time [start]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    run_dummy(numbers)  &lt;span style=&#34;color:#75715e&#34;&gt;# run our inefficient method&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    end_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()  &lt;span style=&#34;color:#75715e&#34;&gt;# get the current time [end]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    duration &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; end_time &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start_time  &lt;span style=&#34;color:#75715e&#34;&gt;# Calculate the duration&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Duration: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;duration&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; seconds&amp;#34;&lt;/span&gt;)  &lt;span style=&#34;color:#75715e&#34;&gt;# Print the duration&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Running this I get the following result:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3.10 assets/dummy/perf_py_proj/before.py
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99992&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99993&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99994&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99995&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99996&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99997&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99998&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99999&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Duration: 36.06884431838989 seconds
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;36 seconds is bad enough for us to pick up a reasonable amount of samples.&lt;/p&gt;
&lt;h2 id=&#34;flamegraphs&#34;&gt;flamegraphs!&lt;/h2&gt;
&lt;p&gt;Now we can create our &lt;a href=&#34;https://github.com/brendangregg/FlameGraph&#34;&gt;FlameGraph&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# record profile to &amp;#34;perf.data&amp;#34; file (default output)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf record -F &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt; -g -- python3.10 assets/dummy/perf_py_proj/before.py
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# read perf.data (created above) and display trace output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf script &amp;gt; out.perf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# fold stack samples into single lines&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# here I reference ~/FlameGraph/ - you can get this from https://github.com/brendangregg/FlameGraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/FlameGraph/stackcollapse-perf.pl out.perf &amp;gt; out.folded
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# generate flamegraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/FlameGraph/flamegraph.pl out.folded &amp;gt; ./assets/perf_example_python3.10.svg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This gives us a nice SVG that visualises the traces:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_example_python3.10.svg&#34; alt=&#34;python 3.10 perf flamegraph&#34; title=&#34;python 3.10 perf flamegraph&#34;&gt;&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t useful &amp;hellip; I can see most of the time was spent in &amp;ldquo;new_keys_object.lto_priv.0&amp;rdquo; but that is meaningless in the context of the code.&lt;/p&gt;
&lt;h2 id=&#34;time-for-python-312&#34;&gt;time for Python 3.12&amp;hellip;&lt;/h2&gt;
&lt;p&gt;First I need to install it - the steps for this vary depending on OS - follow the build instructions here for your environment: &lt;a href=&#34;https://github.com/python/cpython/tree/v3.12.0a3#build-instructions&#34;&gt;https://github.com/python/cpython/tree/v3.12.0a3#build-instructions&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# for me on ubuntu:22.04&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# ensure I have python3-dbg installed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install python3-dbg
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# build python&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export CFLAGS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-fno-omit-frame-pointer -mno-omit-leaf-frame-pointer&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./configure --enable-optimizations
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;make test
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo make install
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;unset CFLAGS
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# after this I reset my systems python3 symlink to 3.10 as 3.12 isn&amp;#39;t yet stable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# for testing python3.12 I&amp;#39;ll call &amp;#34;python3.12&amp;#34; instead of &amp;#34;python3&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ln -sf /usr/local/bin/python3.10 /usr/local/bin/python3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;With that installed I first need to enable perf support. This is detailed in &lt;a href=&#34;https://docs.python.org/3.12/howto/perf_profiling.html&#34;&gt;https://docs.python.org/3.12/howto/perf_profiling.html&lt;/a&gt; and there are three options: 1) an environment variable, 2) an -X option or 3) dynamically using &lt;code&gt;sys&lt;/code&gt;. I&amp;rsquo;ll go for the environment variable approach as I don&amp;rsquo;t mind &lt;em&gt;everything&lt;/em&gt; being profiled for a small script:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PYTHONPERFSUPPORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we simply repeat the process above using the &lt;code&gt;python3.12&lt;/code&gt; binary instead:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# record profile to &amp;#34;perf.data&amp;#34; file (default output)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf record -F &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt; -g -- python3.12 assets/dummy/perf_py_proj/before.py
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# read perf.data (created above) and display trace output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf script &amp;gt; out.perf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# fold stack samples into single lines&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# here I reference ~/FlameGraph/ - you can get this from https://github.com/brendangregg/FlameGraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/FlameGraph/stackcollapse-perf.pl out.perf &amp;gt; out.folded
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# generate flamegraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/FlameGraph/flamegraph.pl out.folded &amp;gt; ./assets/perf_example_python3.12.before.svg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;First we&amp;rsquo;ll take a peek at the report with &lt;code&gt;perf report -g -i perf.data&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_report.png&#34; alt=&#34;python 3.12 perf report output&#34; title=&#34;python 3.12 perf report&#34;&gt;&lt;/p&gt;
&lt;p&gt;Awesome! We can see our Python function names and script names!&lt;/p&gt;
&lt;p&gt;Now we can take a look at the updated SVG that visualises the traces with Python 3.12:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_example_python3.12.before.svg&#34; alt=&#34;python 3.12 perf flamegraph&#34; title=&#34;python 3.12 perf flamegraph&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is already looking much more useful. We see the majority of the time is being spent doing comparisons and in the list_contains method. We can also see the specific file &lt;code&gt;before.py&lt;/code&gt; and method &lt;code&gt;run_dummy&lt;/code&gt; that is calling it.&lt;/p&gt;
&lt;h2 id=&#34;investigation-time--the-fix&#34;&gt;investigation time / the fix&lt;/h2&gt;
&lt;p&gt;Now that we know where in our code the problem is, we can take a look at the source code in CPython to see why the &lt;code&gt;list_contains&lt;/code&gt; method would be so slow: &lt;a href=&#34;https://github.com/python/cpython/blob/199507b81a302ea19f93593965b1e5088195a6c5/Objects/listobject.c#L440&#34;&gt;https://github.com/python/cpython/blob/199507b81a302ea19f93593965b1e5088195a6c5/Objects/listobject.c#L440&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;note: you may not always have access to the source code - in circumstances such as this you can view the disassembly in perf report directly to get some idea of what&amp;rsquo;s going on. I&amp;rsquo;ll add a quick section at the end showing how this looks&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// I found this by going to https://github.com/python/cpython/ and searching for &amp;#34;list_contains&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;list_contains&lt;/span&gt;(PyListObject &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;a, PyObject &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;el)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    PyObject &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;item;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Py_ssize_t i;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; cmp;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, cmp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; ; cmp &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Py_SIZE&lt;/span&gt;(a); &lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;i) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        item &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PyList_GET_ITEM&lt;/span&gt;(a, i);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;Py_INCREF&lt;/span&gt;(item);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        cmp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;PyObject_RichCompareBool&lt;/span&gt;(item, el, Py_EQ);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;Py_DECREF&lt;/span&gt;(item);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; cmp;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Nasty&amp;hellip; looking at this code I can see that each time it is invoked it iterates over the array and performs a comparison against each item. That&amp;rsquo;s far from ideal for our usecase, so lets go back to the Python code we wrote. Our Flamegraph shows us that the problem is in our &lt;code&gt;run_dummy&lt;/code&gt; method:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;run_dummy&lt;/span&gt;(numbers):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; findme &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;100000&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; findme &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; numbers:  &lt;span style=&#34;color:#75715e&#34;&gt;#  &amp;lt;- this is what triggers list_contains&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;found&amp;#34;&lt;/span&gt;, findme)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;missed&amp;#34;&lt;/span&gt;, findme)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We can&amp;rsquo;t really change that line as it is doing what we want it to do - identifying if an integer is in &lt;code&gt;numbers&lt;/code&gt;. Perhaps we can change the &lt;code&gt;numbers&lt;/code&gt; data type to one better suited to lookups. In our existing code we have:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numbers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [i &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;20000000&lt;/span&gt;)]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_time &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; time&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;time()  &lt;span style=&#34;color:#75715e&#34;&gt;# get the current time [start]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    run_dummy(numbers)  &lt;span style=&#34;color:#75715e&#34;&gt;# run our inefficient method&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here we used a LIST data type for our &amp;ldquo;numbers&amp;rdquo;, which under the hood (in CPython) is implemented as dynamically-sized arrays and as such are nowhere near as efficient (O(N)) as the likes of a Hashtable for looking up an item (which is O(1)). A SET on the other hand (another Python data type) is implemented as a Hashtable and would give us the fast lookup we&amp;rsquo;re looking for. Lets change the data type in our Python code and see what the impact is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# we&amp;#39;ll just change this line, casting numbers to a set before running run_dummy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    run_dummy(set(numbers))  &lt;span style=&#34;color:#75715e&#34;&gt;# passing a set() for fast lookups&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now we can repeat the steps as above to generate our new flamegraph:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# record profile to &amp;#34;perf.data&amp;#34; file (default output)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf record -F &lt;span style=&#34;color:#ae81ff&#34;&gt;99&lt;/span&gt; -g -- python3.12 assets/dummy/perf_py_proj/after.py
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99998&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;found &lt;span style=&#34;color:#ae81ff&#34;&gt;99999&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Duration: 0.8350753784179688 seconds
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; perf record: Woken up &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; times to write data &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt; perf record: Captured and wrote 0.039 MB perf.data &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;134&lt;/span&gt; samples&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Already we can see that things have massively improved. Where previously this was taking 36 seconds to run it is now taking 0.8 seconds! Lets continue creating our flamegraph for the new improved code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# read perf.data (created above) and display trace output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf script &amp;gt; out.perf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# fold stack samples into single lines&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# here I reference ~/FlameGraph/ - you can get this from https://github.com/brendangregg/FlameGraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/FlameGraph/stackcollapse-perf.pl out.perf &amp;gt; out.folded
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# generate flamegraph&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;~/FlameGraph/flamegraph.pl out.folded &amp;gt; ./assets/perf_example_python3.12.after.svg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_example_python3.12.after.svg&#34; alt=&#34;python 3.12 perf flamegraph improved&#34; title=&#34;python 3.12 perf flamegraph improved&#34;&gt;&lt;/p&gt;
&lt;p&gt;This is a much healthier looking Flamegraph and our application is now much faster as a result. The perf profiling support in Python 3.12 brings a tremendously useful tool to software engineers that want to deliver fast programs and I&amp;rsquo;m excited to see the impact this will have on the language.&lt;/p&gt;
&lt;h2 id=&#34;bonus-round-what-to-do-when-you-cant-access-the-source-code&#34;&gt;bonus round: what to do when you can&amp;rsquo;t access the source code?&lt;/h2&gt;
&lt;p&gt;Sometimes you don&amp;rsquo;t have access to the underlying code which can make trying to understand what&amp;rsquo;s going on much more difficult. Thankfully &lt;code&gt;perf report&lt;/code&gt; allows us to view the dissassembled code which can help paint a picture of what the machine is actually doing. This is a reasonable first place to look - I tend to prefer the source code if I can get hold of it as it allows me to &lt;code&gt;git blame&lt;/code&gt; / view the associated commits and PRs. To view this you can do the following:&lt;/p&gt;
&lt;p&gt;Open the perf report and select the line we&amp;rsquo;re interested in:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# this assumes we have already ran &amp;#39;perf record&amp;#39; to generate perf.data ...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;perf report -g -i perf.data
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_report_dis.1.png&#34; alt=&#34;perf report dissassembly&#34; title=&#34;perf report dissassembly&#34;&gt;&lt;/p&gt;
&lt;p&gt;Press enter and choose the annotate option:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_report_dis.2.png&#34; alt=&#34;perf report dissassembly&#34; title=&#34;perf report dissassembly&#34;&gt;&lt;/p&gt;
&lt;p&gt;Behold! Here we can see both the C code and the machine instructions. Super useful! You can compare the screenshot below against the code snippet we&amp;rsquo;re interested in: &lt;a href=&#34;https://github.com/python/cpython/blob/199507b81a302ea19f93593965b1e5088195a6c5/Objects/listobject.c#L440&#34;&gt;https://github.com/python/cpython/blob/199507b81a302ea19f93593965b1e5088195a6c5/Objects/listobject.c#L440&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/petermcconnell.com/master/assets/perf_report_dis.3.png&#34; alt=&#34;perf report dissassembly&#34; title=&#34;perf report dissassembly&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;recommended-reading&#34;&gt;recommended reading&lt;/h2&gt;
&lt;p&gt;If this article has given you a taste for performance engineering, I can recommend the following Systems Performance book:&lt;/p&gt;


&lt;a href=&#34;https://www.amazon.com/Systems-Performance-Brendan-Gregg/dp/0136820158?crid=2J7NSUPP1LBQ2&amp;keywords=systems+performance+enterprise+and+the+cloud&amp;qid=1672315747&amp;sprefix=systems+performance%2Caps%2C167&amp;sr=8-1&amp;linkCode=li2&amp;tag=mobile052c67f-20&amp;linkId=042c48313bcd6eae20ae98499600e515&amp;language=en_US&amp;ref_=as_li_ss_il&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; height=&#34;140&#34; src=&#34;https://m.media-amazon.com/images/W/WEBP_402378-T1/images/I/51Drvdub7TL._SX646_BO1,204,203,200_.jpg&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mobile052c67f-20&amp;language=en_US&amp;l=li2&amp;o=1&amp;a=0136820158&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;


</content>
    </item>
    
    <item>
      <title>Monolith vs Microservice repositories - some pros and cons</title>
      <link>https://www.petermcconnell.com/posts/monolith_vs_microservice_repos/</link>
      <pubDate>Mon, 26 Dec 2022 15:01:29 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/monolith_vs_microservice_repos/</guid>
      <description>Monolithic vs Microservice repository management Here we&amp;rsquo;ll take a quick look at monolithic vs microservice repository architecture for managing codebases.
A monolithic repository is a version control system that stores all of the code for a software application in a single, centralized repository. This means that all of the code for an application, including the front-end, back-end, and any additional components, is stored in a single location and managed as a cohesive unit.</description>
      <content>&lt;h1 id=&#34;monolithic-vs-microservice-repository-management&#34;&gt;Monolithic vs Microservice repository management&lt;/h1&gt;
&lt;p&gt;Here we&amp;rsquo;ll take a quick look at monolithic vs microservice repository architecture for managing codebases.&lt;/p&gt;
&lt;p&gt;A monolithic repository is a version control system that stores all of the code for a software application in a single, centralized repository. This means that all of the code for an application, including the front-end, back-end, and any additional components, is stored in a single location and managed as a cohesive unit.&lt;/p&gt;
&lt;p&gt;On the other hand, a microservice repository is a version control system that stores the code for a software application in multiple, smaller repositories, with each repository containing a specific service or component of the application. This means that the code for an application is divided into smaller, more focused units, each with its own repository.&lt;/p&gt;
&lt;p&gt;There are several pros and cons to consider when deciding between a monolithic repository and a microservice repository for your software development project.&lt;/p&gt;
&lt;h2 id=&#34;pros-of-monolithic-repositories&#34;&gt;Pros of Monolithic Repositories&lt;/h2&gt;
&lt;p&gt;Simplicity: Monolithic repositories are simpler to set up and manage than microservice repositories. With all of the code for an application stored in a single location, it is easier to navigate and work with. It also helps implement &amp;ldquo;standard&amp;rdquo; tools, org-wide. Generating reports, such as license compliance, is also a lot more simple.&lt;/p&gt;
&lt;p&gt;Fewer Dependencies: In a monolithic repository, all of the code for an application is stored in a single location, which means that there are fewer dependencies between different components of the application. This can make it easier to understand how the different parts of the application fit together and how changes to one part might affect other parts of the application.&lt;/p&gt;
&lt;p&gt;Easier to Test: Testing a monolithic repository is generally easier than testing a microservice repository because all of the code is stored in a single location. This means that it is easier to set up test environments and run tests on the entire application.&lt;/p&gt;
&lt;h2 id=&#34;cons-of-monolithic-repositories&#34;&gt;Cons of Monolithic Repositories&lt;/h2&gt;
&lt;p&gt;Complexity: As an application grows and becomes more complex, a monolithic repository can become difficult to manage and maintain. With all of the code stored in a single location, it can be challenging to understand how different parts of the application fit together and how changes to one part might affect other parts of the application. Furthermore, trying to map this complexity to appropriate owners can be difficult to setup and maintain.&lt;/p&gt;
&lt;p&gt;Slow Deployment: Because a monolithic repository contains all of the code for an application, deploying updates or changes to the application can be slow and cumbersome. This can be particularly problematic for large applications with many dependencies and integrations. Care needs to be taken in the build tooling to avoid unnecessary cycles.&lt;/p&gt;
&lt;p&gt;Politics / Co-ownership: service owners are no longer repository administrators by default. Implementing change to the general build tooling, for example, requires careful coordination amongst external teams.&lt;/p&gt;
&lt;h2 id=&#34;pros-of-microservice-repositories&#34;&gt;Pros of Microservice Repositories&lt;/h2&gt;
&lt;p&gt;Strong Ownership: with microservice repositories teams can manage their own repos, implementing the tooling which best fits the need for their team without having to consult too many external teams beforehand.&lt;/p&gt;
&lt;p&gt;Improved Deployment: Because each service or component of an application is stored in a separate repository, it is easier to deploy updates or changes to a specific service or component without affecting the rest of the application. It allows the CI/CD configuration to be very lean. This can make deployment faster and more efficient. It&amp;rsquo;s also more common here for service teams to own their CI/CD pipelines.&lt;/p&gt;
&lt;p&gt;Better Organization: With each service or component of an application stored in a separate repository, it is easier to understand how different parts of the application fit together and how changes to one part might affect other parts of the application. This can improve organization and make it easier to manage and maintain the application. At the least it requires less cognitive load to understand parts of the system on their own.&lt;/p&gt;
&lt;h2 id=&#34;cons-of-microservice-repositories&#34;&gt;Cons of Microservice Repositories&lt;/h2&gt;
&lt;p&gt;Complexity: Microservice repositories can be more complex to set up and manage than monolithic repositories. With each service or component of an application stored in a separate repository, there are more dependencies and integrations to manage and maintain.&lt;/p&gt;
&lt;p&gt;More Dependencies: With each service or component of an application stored in their own repositories it&amp;rsquo;s harder to control the external dependencies the entire system is using. For example, repo A may use version 1.0.1 of a library, whilst repo B uses 1.0.2. Standardizing on libraries and binaries is very difficult and the result can be a lot of bloat to the sytem as a whole.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Having seen both in the wild my recommendation would be to go with a monolithic repository if you have people to throw at the tooling - this will make some eyes roll and implementing change to parts of the repo which affect all teams will feel slow, but frankly this is a good pain to feel - without it, people will choose the path of least resistence which often results in growing tech debt, system bloat and disparity in standards and pulling that back together retrospectively can be painful.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>chatGPT - building an automated database testing tool</title>
      <link>https://www.petermcconnell.com/posts/ai_db_testing/</link>
      <pubDate>Thu, 08 Dec 2022 11:41:50 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/ai_db_testing/</guid>
      <description>Creating an automated database testing tool with ChatGPT Last night I thought I&amp;rsquo;d try to get ChatGPT to make an automated database testing tool and the results were quite promising.
In conclusion, with guidance, it was able to build a project from scratch that ran a python script and postgres database. It generated some random schema and values for the randomly generated tables. It provided a Python script which would introspect the database and execute queries against it.</description>
      <content>&lt;h2 id=&#34;creating-an-automated-database-testing-tool-with-chatgpt&#34;&gt;Creating an automated database testing tool with ChatGPT&lt;/h2&gt;
&lt;p&gt;Last night I thought I&amp;rsquo;d try to get ChatGPT to make an automated database
testing tool and the results were quite promising.&lt;/p&gt;
&lt;p&gt;In conclusion, with guidance, it was able to build a project from scratch that
ran a python script and postgres database. It generated some random schema and
values for the randomly generated tables. It provided a Python script which
would introspect the database and execute queries against it.&lt;/p&gt;
&lt;p&gt;Did it all work out of the box? No. There are some bugs to fix in the python
script it generated. However the effort to go in and fix those is not high and
certainly the whole end-to-end process is cheaper, time-wise, compared to
starting from scratch.&lt;/p&gt;
&lt;p&gt;I found that the bugs it encountered were largely due to my lack of clarity or
ordering of questions posed to it. It was quite capable of fixing its own
mistakes / updating the existing code to match the new requirements when
requested to do so.&lt;/p&gt;
&lt;p&gt;The only &lt;em&gt;real&lt;/em&gt; issue I encountered were general API errors that one would
expect of something so popular in an early preview state.&lt;/p&gt;
&lt;p&gt;I came away from this experiment viewing ChatGPT and whatever follows it as a
really useful development aide for those who already know how to program. It
helped me build a tool faster than I could have had I sat down to do it from
scratch. I don&amp;rsquo;t view it as a replacement for software engineers yet for two
main reasons - firstly: for non-trivial applications I suspect the person
feeding requirements into the system (or &amp;ldquo;prompt engineer&amp;rdquo;) needs to have a
reasonable idea of how to build software in the first place, so as to know how
to form requests and to correct mistakes / close gaps. secondly: the code being
generated isn&amp;rsquo;t always sound - without an experienced engineer reviewing and
taking ownership of whatever code is produced (ownership being important for
maintainence reasons) then there&amp;rsquo;s little guarantee that you will get what you
are hoping for.&lt;/p&gt;
&lt;p&gt;However; this is still very early days. Can the problems outlined be closed
further? Absolutely. Will this sort of tooling be &amp;ldquo;bad&amp;rdquo; for software
engineering as a whole, long-term? Perhaps. Personally I&amp;rsquo;m very excited to have
this tool in my arsenal - already it has allowed me to scaffold prototype
applications quickly. Would I use it for production code in a workplace? No
more or less than I would snippets from stackoverflow or it&amp;rsquo;s ilk. For now.&lt;/p&gt;
&lt;p&gt;Github repository: &lt;a href=&#34;https://github.com/peter-mcconnell/gpt_sql_test_generator&#34;&gt;https://github.com/peter-mcconnell/gpt_sql_test_generator&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Screenshots:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/2.png&#34; alt=&#34;step 2&#34; title=&#34;step 2&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/3.png&#34; alt=&#34;step 3&#34; title=&#34;step 3&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/4.png&#34; alt=&#34;step 4&#34; title=&#34;step 4&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/5.png&#34; alt=&#34;step 5&#34; title=&#34;step 5&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/6.png&#34; alt=&#34;step 6&#34; title=&#34;step 6&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/7.png&#34; alt=&#34;step 7&#34; title=&#34;step 7&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/8.png&#34; alt=&#34;step 8&#34; title=&#34;step 8&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/9.png&#34; alt=&#34;step 9&#34; title=&#34;step 9&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/10.png&#34; alt=&#34;step 10&#34; title=&#34;step 10&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/11.png&#34; alt=&#34;step 11&#34; title=&#34;step 11&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/12.png&#34; alt=&#34;step 12&#34; title=&#34;step 12&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/13.png&#34; alt=&#34;step 13&#34; title=&#34;step 13&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/14.png&#34; alt=&#34;step 14&#34; title=&#34;step 14&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/15.png&#34; alt=&#34;step 15&#34; title=&#34;step 15&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/peter-mcconnell/gpt_sql_test_generator/master/media/16.png&#34; alt=&#34;step 16&#34; title=&#34;step 16&#34;&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>chatGPT - building a virtual machine</title>
      <link>https://www.petermcconnell.com/posts/chatgpt/</link>
      <pubDate>Mon, 05 Dec 2022 14:16:04 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/chatgpt/</guid>
      <description>:mind-blown:
https://www.engraved.blog/building-a-virtual-machine-inside/</description>
      <content>&lt;p&gt;:mind-blown:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.engraved.blog/building-a-virtual-machine-inside/&#34;&gt;https://www.engraved.blog/building-a-virtual-machine-inside/&lt;/a&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Vimtips</title>
      <link>https://www.petermcconnell.com/posts/vimtips/</link>
      <pubDate>Thu, 01 Dec 2022 11:36:49 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/vimtips/</guid>
      <description>I stumbled across a nice vim tips resource today:
https://thevaluable.dev/vim-advanced/</description>
      <content>&lt;p&gt;I stumbled across a nice vim tips resource today:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://thevaluable.dev/vim-advanced/&#34;&gt;https://thevaluable.dev/vim-advanced/&lt;/a&gt;&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Hugo</title>
      <link>https://www.petermcconnell.com/posts/hugo/</link>
      <pubDate>Tue, 29 Nov 2022 23:16:21 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/hugo/</guid>
      <description>How I set this website up, for free tldr; Hugo + Github + AWS Amplify. Easy peasy. total time: 1 hour (mostly spent writing content)
Some parameters:
free templates. I&amp;rsquo;m no designer static web asset output is fine. I&amp;rsquo;m not building a backend (yet) but having the option to do so is a bonus this project should be as low effort as possible so; no html / css / js where possible also; automated deploys on push to $branch ideally I don&amp;rsquo;t need to maintain ci to do this.</description>
      <content>&lt;h2 id=&#34;how-i-set-this-website-up-for-free&#34;&gt;How I set this website up, for free&lt;/h2&gt;
&lt;p&gt;tldr; Hugo + Github + AWS Amplify. Easy peasy.
total time: 1 hour (mostly spent writing content)&lt;/p&gt;
&lt;p&gt;Some parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;free templates. I&amp;rsquo;m no designer&lt;/li&gt;
&lt;li&gt;static web asset output is fine. I&amp;rsquo;m not building a backend (yet)
&lt;ul&gt;
&lt;li&gt;but having the option to do so is a bonus&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;this project should be as low effort as possible
&lt;ul&gt;
&lt;li&gt;so; no html / css / js where possible&lt;/li&gt;
&lt;li&gt;also; automated deploys on push to $branch
&lt;ul&gt;
&lt;li&gt;ideally I don&amp;rsquo;t need to maintain ci to do this. lowest poss. effort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;as cheap to host as possible. free, ideally&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In summary I want to only write page content. No code. No pipelines. No buttons
to click. But I still want uri&amp;rsquo;s, the abililty to render rich media and a pretty
template that I need to do nothing with. And I&amp;rsquo;d like to not pay for any of it.&lt;/p&gt;
&lt;h3 id=&#34;static-web-files&#34;&gt;static web files&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;ve heard about Hugo for years but never had the opportunity to try it out and
knew from the criteria I had that it should solve getting me the static assets
quickly. Even if it didn&amp;rsquo;t turn out to be the &lt;em&gt;right&lt;/em&gt; tool, I knew
experimentation would be cheap.&lt;/p&gt;
&lt;p&gt;Install was super easy: &lt;a href=&#34;https://gohugo.io/installation/linux/&#34;&gt;https://gohugo.io/installation/linux/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I then jumped over to &lt;a href=&#34;https://gohugo.io/getting-started/quick-start/&#34;&gt;https://gohugo.io/getting-started/quick-start/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This quick start guide felt like all I&amp;rsquo;d need so I went searching for a theme.
The power of search engines brought me to &lt;a href=&#34;https://hugothemesfree.com/&#34;&gt;https://hugothemesfree.com/&lt;/a&gt;. The tags
on the right of this page helped me find the terminal theme quickly
(&lt;a href=&#34;https://hugothemesfree.com/a-simple-retro-theme-for-hugo/&#34;&gt;https://hugothemesfree.com/a-simple-retro-theme-for-hugo/&lt;/a&gt;) which reminded me
of my old i3 + polybar configuration. MIT licensed too. Bingo.&lt;/p&gt;
&lt;p&gt;A few &lt;code&gt;hugo new posts/thing.md&lt;/code&gt; and &lt;code&gt;hugo new otherthing.md&lt;/code&gt;&amp;rsquo;s later and I had
my static website files. I opted to bake the theme into the repo so that I
could mutate the files. Created a new repository
(&lt;a href=&#34;https://github.com/peter-mcconnell/petermcconnell.com&#34;&gt;https://github.com/peter-mcconnell/petermcconnell.com&lt;/a&gt;) and threw my files
there for safe keeping. Now I just needed somewhere to host it.&lt;/p&gt;
&lt;h3 id=&#34;a-search-for-cheap-hosting-solutions&#34;&gt;a search for cheap hosting solutions&lt;/h3&gt;
&lt;p&gt;The most obvious route was github pages but I wanted to look at other options
which offered some extra features should I need them in the future.&lt;/p&gt;
&lt;p&gt;A quick look around lead me to AWS Amplify - a service I admittedly hadn&amp;rsquo;t
heard of before. A quick look over the marketing material
(&lt;a href=&#34;https://aws.amazon.com/getting-started/hands-on/build-serverless-web-app-lambda-apigateway-s3-dynamodb-cognito/module-1/&#34;&gt;https://aws.amazon.com/getting-started/hands-on/build-serverless-web-app-lambda-apigateway-s3-dynamodb-cognito/module-1/&lt;/a&gt;)
looked like it was interesting; Lambda, API Gateway, Dynamo DB - all things
that pluck on my cheap-skate heart strings. Pricing:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/amplify/pricing/&#34;&gt;https://aws.amazon.com/amplify/pricing/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m no Madonna - I think my personal website is probably a safe bet to do
&amp;ldquo;free tier&amp;rdquo; numbers (&amp;lt;500k req.|15Gb egress|100Gb req. duration per month).&lt;/p&gt;
&lt;p&gt;I logged into my personal AWS account, went through the little Amplify setup
wizard, pointed it to my github repo, updated my DNS records to whatever the
wizard was telling me to and voila - &lt;a href=&#34;https://www.petermcconnell.com/&#34;&gt;https://www.petermcconnell.com/&lt;/a&gt; is up and
running.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Current Reading</title>
      <link>https://www.petermcconnell.com/posts/current-reading/</link>
      <pubDate>Tue, 29 Nov 2022 20:30:52 +0000</pubDate>
      
      <guid>https://www.petermcconnell.com/posts/current-reading/</guid>
      <description>The Linux Programming Interface I should have read this years ago. It&amp;rsquo;s a big boi, but if you work around linux or are interested in it - this book is a critical primer on many of the core topics you&amp;rsquo;ll need to really understand what&amp;rsquo;s going on. I binged this book on the first pass over multiple weeks - deliberately skipping implementing the code examples, opting to just read them / ensure I understood them.</description>
      <content>&lt;h2 id=&#34;the-linux-programming-interface&#34;&gt;The Linux Programming Interface&lt;/h2&gt;
&lt;p&gt;I should have read this years ago. It&amp;rsquo;s a big boi, but if you work around linux
or are interested in it - this book is a critical primer on many of the core
topics you&amp;rsquo;ll need to really understand what&amp;rsquo;s going on. I binged this book on
the first pass over multiple weeks - deliberately skipping implementing the
code examples, opting to just read them / ensure I understood them. I choose to
do this so that I could get over as much content as possible, with the view of
circling back over the examples once I&amp;rsquo;m finished The C Programming Language
book so that I can make better decisions about the code I&amp;rsquo;m writing.&lt;/p&gt;


&lt;a href=&#34;https://www.amazon.com/Linux-Programming-Interface-System-Handbook/dp/1593272200?crid=1DXMBKFNYR6I4&amp;keywords=the+linux+programming+interface&amp;qid=1672318042&amp;sprefix=the+linux+programming+interfa%2Caps%2C183&amp;sr=8-1&amp;linkCode=li2&amp;tag=mobile052c67f-20&amp;linkId=5a628a4a0310f010f8843eec26340d21&amp;language=en_US&amp;ref_=as_li_ss_il&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;https://s.cdnshm.com/catalog/pt/t/33820519/linux-programming-interface.jpg&#34; height=&#34;180&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mobile052c67f-20&amp;language=en_US&amp;l=li2&amp;o=1&amp;a=1593272200&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;


&lt;h2 id=&#34;the-c-programming-language&#34;&gt;The C Programming Language&lt;/h2&gt;
&lt;p&gt;I generally try to avoid taking on multiple books but I figured as the above is
so large and much of the books example code is given in C, then this book which
I&amp;rsquo;m long overdue on would be a nice complement.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s fine. Concise and clear wording; unlike the print quality, unfortunately.
This books print looks like it was hand-painted by a very nervous individual trying
to hit a deadline in the dark. Print-quality aside, I&amp;rsquo;d say this is an
important book to read, but not much of a page-turner. For me the biggest
advantage of the book was seeing syscall libraries in action and also
appreciating more about what cpp gives us.&lt;/p&gt;


&lt;a href=&#34;https://www.amazon.com/Programming-Language-2nd-Brian-Kernighan/dp/0131103628?crid=18TBDWGH446SY&amp;keywords=the+c+programming+language&amp;qid=1672318154&amp;sprefix=the+c+progr%2Caps%2C161&amp;sr=8-1&amp;linkCode=li2&amp;tag=mobile052c67f-20&amp;linkId=a74299466e17d38e6564338bf456bedd&amp;language=en_US&amp;ref_=as_li_ss_il&#34; target=&#34;_blank&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;https://m.media-amazon.com/images/I/C1bOAdsnZnS._CR504,0,3024,3024_UX256.jpg&#34; &gt;&lt;/a&gt;&lt;img src=&#34;https://ir-na.amazon-adsystem.com/e/ir?t=mobile052c67f-20&amp;language=en_US&amp;l=li2&amp;o=1&amp;a=0131103628&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;


&lt;h2 id=&#34;up-next&#34;&gt;Up next&lt;/h2&gt;
&lt;p&gt;I have two &amp;ldquo;crackers&amp;rdquo; on my desk. Really looking forward to these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux Kernel Development (&lt;a href=&#34;https://amzn.to/3hXuWTw&#34;&gt;https://amzn.to/3hXuWTw&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Systems Performance (&lt;a href=&#34;https://amzn.to/3I9iU49&#34;&gt;https://amzn.to/3I9iU49&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
  </channel>
</rss>
